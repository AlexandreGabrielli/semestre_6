{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c7/HEIG-VD_Logo_96x29_RVB_ROUGE.png\" alt=\"HEIG-VD Logo\" width=\"250\" /> \n",
    "\n",
    "# Cours TAL - Laboratoire 2\n",
    "# Mise en œuvre et évaluation de *POS taggers* pour le français\n",
    "\n",
    "**Objectif**\n",
    "\n",
    "Appliquer des étiqueteurs morphosyntaxiques (POS taggers) disponibles dans NLTK et dans les outils Stanford NLP à des textes français, puis quantifier leurs performances.\n",
    "\n",
    "**Instructions initiales**\n",
    "\n",
    "* Télécharger [l'archive ZIP fournie par l'enseignant](https://drive.switch.ch/index.php/s/5ZNllZOApTWHGwH) (mot de passe = reference).\n",
    "* Placer les trois fichiers qu'elle contient dans le même dossier que le notebook.\n",
    "* Ce sont des textes en français annotés avec les POS tags, provenant du projet ([Universal Dependencies](https://github.com/UniversalDependencies/UD_French-GSD)), et légèrement modifiés.\n",
    "  - le fichier `fr-ud-train.conllu3` est destiné à l'entraînement\n",
    "  - le fichier `fr-ud-dev.conllu3` est destiné aux tests préliminaires et aux réglages des paramètres\n",
    "  - le fichier `fr-ud-test.conllu3` est destiné à l'évaluation finale.\n",
    "\n",
    "**Questions préliminaires**\n",
    "\n",
    "* En inspectant les fichiers, veuillez indiquer le numéro de la colonne où se trouvent les mots, et celui de la colonne où se trouvent leur étiquettes morpho-syntaxiques (*POS tags*).\n",
    "```\n",
    "Les étiquéttes se trouve dans la col 3 ( 0 => numero, 1 => mot, 2 => normalisation, 3 => étiquette ) \n",
    "```\n",
    "* Veuillez chercher sur le Web la liste des *POS tags* du projet Universal Dependencies, avec leurs définitions, et indiquer l'URL ci-dessous.\n",
    "```\n",
    "https://universaldependencies.org/u/pos/\n",
    "````\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Veuillez déterminer et afficher le nombre de tokens de chacun des trois fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of token f_1 :38308\n",
      "number of token f_2 :10714\n",
      "number of token f_3 :380925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Alexandre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "f_1=open(\"fr-ud-dev.conllu3\", \"r\",encoding=\"utf_8\")\n",
    "f_2=open(\"fr-ud-test.conllu3\",\"r\",encoding=\"utf_8\")\n",
    "f_3=open(\"fr-ud-train.conllu3\",\"r\",encoding=\"utf_8\")\n",
    "\n",
    "if f_1.mode == 'r':\n",
    "    contents_1  =len(f_1.readlines())\n",
    "if f_2.mode == 'r':\n",
    "    contents_2  =len(f_2.readlines())\n",
    "if f_3.mode == 'r':\n",
    "    contents_3  =len(f_3.readlines())\n",
    "\n",
    "f_1.close()\n",
    "f_2.close()\n",
    "f_3.close()\n",
    "\n",
    "print(\"number of token f_1 :\" + str(contents_1))\n",
    "print(\"number of token f_2 :\" + str(contents_2))\n",
    "print(\"number of token f_3 :\" + str(contents_3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Évaluer le Stanford POS tagger avec les modèles fournis pour le français\n",
    "\n",
    "L'Université de Stanford fournit un étiqueteur morpho-syntaxique (POS tagger) qui utilise l'apprentissage automatique (https://nlp.stanford.edu/software/tagger.html) appelé Maxent Tagger.  Le tagger et ses modèles multilingues peuvent être téléchargés à l'URL ci-dessus (archive ZIP suivant le lien *Download > full Stanford Tagger version 3.9.2*, 130 MB environ).  \n",
    "\n",
    "Pour simplifier, on vous propose de télécharger séparément le programme Java [stanford-postagger.jar](https://drive.switch.ch/index.php/s/hMY6yO7lmoQJuS3) et le modèle français [french-ud.tagger](https://drive.switch.ch/index.php/s/4HSqKRTTTkCgPfB) fournis par l'enseignant (mot de passe = reference).  Enregistrez ces deux fichiers dans le même dossier que ce notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Maxent Tagger est en Java, et peut être exécuté depuis ce notebook avec un appel Java en ligne de commande.  Pour exécuter une commande système depuis le notebook, ajouter '!' devant (par exemple `! dir` ou `! ls`).  Utilisez la [documentation du Maxent Tagger](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/tagger/maxent/MaxentTagger.html), et plus précisément la section *Tagging and Testing from the command line*, pour comprendre comment l'invoquer.  Java doit être installé sur votre système, et si nécessaire, exécuter :\n",
    "```python\n",
    "import os\n",
    "java_path = 'C:/Program Files (x86)/Java/jdk1.8.0_20/bin/java.exe'  # votre chemin de java.exe\n",
    "os.environ['JAVA_HOME'] = java_path   # attention aux slash (pas backslash sous Windows)\n",
    "```\n",
    "*Note* : il est également possible d'appeler ce tagger avec des commandes NLTK grâce au module [nltk.tag.stanford](https://www.nltk.org/_modules/nltk/tag/stanford.html) mais la gestion des *paths* entre Java, les classes et les modèles peut être compliquée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#for windows we need to import os for ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "Appliquez le Maxent Tagger pour étiqueter le fichier `fr-ud-dev.conllu3` et demandez à Maxent Tagger de mesurer la qualité par comparaison à une l'annotation de référence fournie dans le fichier. Quels sont les scores obtenus ?  Quel est le nombre le plus important?  Indiquez ces réponses en commentaires du code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading default properties from tagger french-ud.tagger\n",
      "Loading POS tagger from french-ud.tagger ... done [0.2 sec].\n",
      "Tagged 36830 words at 35277.78 words per second.\n",
      "Model french-ud.tagger has xSize=304855, ySize=18, and numFeatures=104853.\n",
      "Results on 1478 sentences and 36830 words, of which 3049 were unknown.\n",
      "Total sentences right: 144 (9.742896%); wrong: 1334 (90.257104%).\n",
      "Total tags right: 32360 (87.863155%); wrong: 4470 (12.136845%).\n",
      "Unknown words right: 2232 (73.204329%); wrong: 817 (26.795671%).\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "!java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger -model french-ud.tagger -testFile \"format=TSV,wordColumn=1,tagColumn=3,fr-ud-dev.conllu3\" -verboseResults false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même, appliquez le Maxent Tagger pour étiqueter le fichier `fr-ud-test.conllu3` et indiquez la précision du tagger en commentaires du code (#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading default properties from tagger french-ud.tagger\n",
      "Loading POS tagger from french-ud.tagger ... done [0.2 sec].\n",
      "Tagged 10298 words at 48805.69 words per second.\n",
      "Model french-ud.tagger has xSize=304855, ySize=18, and numFeatures=104853.\n",
      "Results on 416 sentences and 10298 words, of which 250 were unknown.\n",
      "Total sentences right: 0 (0.000000%); wrong: 416 (100.000000%).\n",
      "Total tags right: 270 (2.621868%); wrong: 10028 (97.378132%).\n",
      "Unknown words right: 0 (0.000000%); wrong: 250 (100.000000%).\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "!java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger -model french-ud.tagger -testFile \"format=TSV,wordColumn=0,tagColumn=3,fr-ud-test.conllu3\" -verboseResults false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question subsidiare** : combien de phrases et de mots le tagger trouve-t-il dans les fichiers `fr-ud-dev.conllu3` et `fr-ud-test.conllu3` ?  Comparez avec votre propre estimation du nombre de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire vos réponses ci-dessous, en commentaires.\n",
    "# le tagger trouve 36830 mots sur le fichiers dev et nous avons calculer 38308 mots\n",
    "# pour test nous trouvons 10298 avec le tagger contre 10714\n",
    "#c'est petite différence sont du au espace blanc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : Entraîner le Stanford POS tagger pour obtenir de nouveaux modèles\n",
    "\n",
    "Le but de cette partie est d'entraîner le Maxent Tagger sur les données UD en français (`fr-ud-train.conllu3`), puis de comparer le modèle obtenu avec les modèles fournis par Stanford pour le français, testés dans la partie 1A.  \n",
    "\n",
    "Suivre la [documentation de Maxent Tagger](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/tagger/maxent/MaxentTagger.html) pour l'entraîner sur le fichier `fr-ud-train.conllu3` et le tester sur `fr-ud-test.conllu3`.  Regardez la section *Training from the command line*. \n",
    "\n",
    "La configuration du système pour effectuer l'entraînement est donnée dans un fichier texte, qui peut être produit en suivant la documentation (option `-genprops` pour obtenir un template qui sera édité), soit en s'inspirant du fichier [french-ud.tagger.props](https://drive.switch.ch/index.php/s/gHlam9S74HG2Q4X) accompagnant le modèle `french-ud.tagger` que vous avez utilisé ci-dessus.  Pensez à donner un nouveau nom à votre fichier modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "* Créez un fichier `myFrench-ud.tagger.props` qui aboutit à un bon entraînement.  Vous pourrez expérimenter plusieurs fois et proposer le meilleur fichier.  Citez dans le notebook les paramètres sur lesquels vous avez agi.\n",
    "\n",
    "* Lancez l'entraînement sur le fichier `fr-ud-train.conllu3` (s'il ne tient pas en mémoire, utilisez seulement `fr-ud-dev.conllu3`). Pendant l’entraînement (> 10 minutes, 500 itérations), regardez la suite du travail.\n",
    "\n",
    "* Évaluez votre modèle comme ci-dessus (sur `dev` et sur `test`).  Quel modèle est meilleur, le vôtre ou celui fourni par Stanford ?  Formulez une hypothèse expliquant ce résultat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Sample properties file for maxent tagger. This file is used for three main\n",
      "## operations: training, testing, and tagging. It may also be used to dump\n",
      "## the contents of a model.\n",
      "## To train or test a model, or to tag something, run:\n",
      "##   java edu.stanford.nlp.tagger.maxent.MaxentTagger -prop <properties file>\n",
      "## Arguments can be overridden on the commandline, e.g.:\n",
      "##   java ....MaxentTagger -prop <properties file> -testFile /other/file \n",
      "\n",
      "# Model file name (created at train time; used at tag and test time)\n",
      "# (you can leave this blank and specify it on the commandline with -model)\n",
      "# model = \n",
      "\n",
      "# Path to file to be operated on (trained from, tested against, or tagged)\n",
      "# Specify -textFile <filename> to tag text in the given file, -trainFile <filename> to\n",
      "# to train a model using data in the given file, or -testFile <filename> to test your\n",
      "# model using data in the given file.  Alternatively, you may specify\n",
      "# -dump <filename> to dump the parameters stored in a model or \n",
      "# -convertToSingleFile <filename> to save an old, multi-file model (specified as -model)\n",
      "# to the new single file format.  The new model will be saved in the file filename.\n",
      "# If you choose to convert an old file, you must specify \n",
      "# the correct 'arch' parameter used to create the original model.\n",
      "# trainFile = \n",
      "\n",
      "# Path to outputFile to write tagged output to.\n",
      "# If empty, stdout is used.\n",
      "# outputFile = \n",
      "\n",
      "# Output format. One of: slashTags (default), xml, or tsv\n",
      "# outputFormat = slashTags\n",
      "\n",
      "# Output format options. Comma separated list.\n",
      "# currently \"lemmatize\" and \"keepEmptySentences\" are supported.\n",
      "# outputFormatOptions = \n",
      "\n",
      "# Tag separator character that separates word and pos tags\n",
      "# (for both training and test data) and used for\n",
      "# separating words and tags in slashTags format output.\n",
      "# tagSeparator = /\n",
      "\n",
      "# Encoding format in which files are stored.  If left blank, UTF-8 is assumed.\n",
      "# encoding = UTF-8\n",
      "\n",
      "# A couple flags for controlling the amount of output:\n",
      "# - print extra debugging information:\n",
      "# verbose = false\n",
      "# - print intermediate results:\n",
      "# verboseResults = true\n",
      "######### parameters for tag and test operations #########\n",
      "\n",
      "# Class to use for tokenization. Default blank value means Penn Treebank\n",
      "# tokenization.  If you'd like to just assume that tokenization has been done,\n",
      "# and the input is whitespace-tokenized, use\n",
      "# edu.stanford.nlp.process.WhitespaceTokenizer or set tokenize to false.\n",
      "# tokenizerFactory = \n",
      "\n",
      "# Options to the tokenizer.  A comma separated list.\n",
      "# This depends on what the tokenizer supports.\n",
      "# For PTBTokenizer, you might try options like americanize=false\n",
      "# or asciiQuotes (for German!).\n",
      "# tokenizerOptions = \n",
      "\n",
      "# Whether to tokenize text for tag and test operations. Default is true.\n",
      "# If false, your text must already be whitespace tokenized.\n",
      "# tokenize = true\n",
      "\n",
      "# Write debugging information (words, top words, unknown words). Useful for\n",
      "# error analysis. Default is false.\n",
      "# debug = false\n",
      "\n",
      "# Prefix for debugging output (if debug == true). Default is to use the\n",
      "# filename from 'file'\n",
      "# debugPrefix = \n",
      "\n",
      "######### parameters for training  #########\n",
      "\n",
      "# model architecture: This is one or more comma separated strings, which\n",
      "# specify which extractors to use. Some of them take one or more integer\n",
      "# or string \n",
      "# (file path) arguments in parentheses, written as m, n, and s below:\n",
      "# 'left3words', 'left5words', 'bidirectional', 'bidirectional5words',\n",
      "# 'generic', 'sighan2005', 'german', 'words(m,n)', 'wordshapes(m,n)',\n",
      "# 'biwords(m,n)', 'lowercasewords(m,n)', 'vbn(n)', distsimconjunction(s,m,n)',\n",
      "# 'naacl2003unknowns', 'naacl2003conjunctions', 'distsim(s,m,n)',\n",
      "# 'suffix(n)', 'prefix(n)', 'prefixsuffix(n)', 'capitalizationsuffix(n)',\n",
      "# 'wordshapes(m,n)', 'unicodeshapes(m,n)', 'unicodeshapeconjunction(m,n)',\n",
      "# 'lctagfeatures', 'order(k)', 'chinesedictionaryfeatures(s)'.\n",
      "# These keywords determines the features extracted.  'generic' is language independent.\n",
      "# distsim: Distributional similarity classes can be an added source of information\n",
      "# about your words. An English distsim file is included, or you can use your own.\n",
      "# arch = \n",
      "\n",
      "# 'wordFunction'.  A function applied to the text before training or tagging.\n",
      "# For example, edu.stanford.nlp.util.LowercaseFunction\n",
      "# This function turns all the words into lowercase\n",
      "# The function must implement java.util.function.Function<String, String>\n",
      "# Blank means no preprocessing function\n",
      "# wordFunction = \n",
      "\n",
      "# 'language'.  This is really the tag set which is used for the\n",
      "# list of open-class tags, and perhaps deterministic  tag\n",
      "# expansion). Currently we have 'english', 'arabic', 'german', 'chinese'\n",
      "# or 'polish' predefined. For your own language, you can specify \n",
      "# the same information via openClassTags or closedClassTags below\n",
      "# (only ONE of these three options may be specified). \n",
      "# 'english' means UPenn English treebank tags. 'german' is STTS\n",
      "# 'chinese' is CTB, and Arabic is an expanded Bies mapping from the ATB\n",
      "# 'polish' means some tags that some guy on the internet once used. \n",
      "# See the TTags class for more information.\n",
      "# lang = \n",
      "\n",
      "# a space-delimited list of open-class parts of speech\n",
      "# alternatively, you can specify language above to use a pre-defined list or specify the closed class tags (below)\n",
      "# openClassTags = \n",
      "\n",
      "# a space-delimited list of closed-class parts of speech\n",
      "# alternatively, you can specify language above to use a pre-defined list or specify the open class tags (above)\n",
      "# closedClassTags = \n",
      "\n",
      "# A boolean indicating whether you would like the trained model to set POS tags as closed\n",
      "# based on their frequency in training; default is false.  The frequency threshold can be set below. \n",
      "# This option is ignored if any of {openClassTags, closedClassTags, lang} are specified.\n",
      "# learnClosedClassTags = \n",
      "\n",
      "# Used only if learnClosedClassTags=true.  Tags that have fewer tokens than this threshold are\n",
      "# considered closed in the trained model.\n",
      "# closedClassTagThreshold = \n",
      "\n",
      "# search method for optimization. Normally use the default 'qn'. choices: 'qn' (quasi-Newton),\n",
      "# 'cg' (conjugate gradient, 'owlqn' (L1 regularization) or 'iis' (improved iterative scaling)\n",
      "# search = qn\n",
      "\n",
      "# for conjugate gradient or quasi-Newton search, sigma-squared smoothing/regularization\n",
      "# parameter. if left blank, the default is 0.5, which is usually okay\n",
      "# sigmaSquared = 0.5\n",
      "\n",
      "# for OWLQN search, regularization\n",
      "# parameter. if left blank, the default is 1.0, which is usually okay\n",
      "# regL1 = 1.0\n",
      "\n",
      "# For improved iterative scaling, the number of iterations, otherwise ignored\n",
      "# iterations = 100\n",
      "\n",
      "# rare word threshold. words that occur less than this number of\n",
      "# times are considered rare words.\n",
      "# rareWordThresh = 5\n",
      "\n",
      "# minimum feature threshold. features whose history appears less\n",
      "# than this number of times are ignored.\n",
      "# minFeatureThresh = 5\n",
      "\n",
      "# current word feature threshold. words that occur more than this\n",
      "# number of times will generate features with all of their occurring\n",
      "# tags.\n",
      "# curWordMinFeatureThresh = 2\n",
      "\n",
      "# rare word minimum feature threshold. features of rare words whose histories\n",
      "# appear less than this times will be ignored.\n",
      "# rareWordMinFeatureThresh = 10\n",
      "\n",
      "# very common word threshold. words that occur more than this number of\n",
      "# times will form an equivalence class by themselves. ignored unless\n",
      "# you are using equivalence classes.\n",
      "# veryCommonWordThresh = 250\n",
      "\n",
      "# sgml = \n",
      "# tagInside = \n",
      "\n",
      "# testFile and textFile can use multiple threads to process text.\n",
      "# nthreads = 1\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "!java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger -genprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "#train\n",
    "!java -cp stanford-postagger.jar edu.stanford.nlp.tagger.maxent.MaxentTagger -props french-ud.tagger.props "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n",
    "!java edu.stanford.nlp.tagger.maxent.MaxentTagger -model french-ud.tagger -testFile fr-ud-train.conllu3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3 : entraîner un POS tagger pour le français dans NLTK\n",
    "\n",
    "Le but de cette partie est d'utiliser le POS tagger *Averaged Perceptron* de NLTK, en l'entraînant pour le français sur les mêmes données que ci-dessus.  \n",
    "\n",
    "Notez que pour l'anglais, des taggers pré-entraînés sont disponibles dans NLTK, comme expliqué au [Chapitre 5.1 du livre NLTK](http://www.nltk.org/book/ch05.html) : on peut écrire `nltk.pos_tag(sentence)` où *sentence* est une phrase tokenisée. L'étiquetage morpho-syntaxique produira des paires ('mot', 'TAG').\n",
    "\n",
    "**Première étape**\n",
    "\n",
    "Importer les textes annotés `fr-ud-XXXX.conllu3` grâce à des objets `ConllCorpusReader`.  Consultez le mode d'emploi de cette classe directement dans [son code source](https://www.nltk.org/_modules/nltk/corpus/reader/conll.html#ConllCorpusReader), pour déterminer comment lire un fichier en créant un objet `ConllCorpusReader`.  Chargez les trois fichiers, dans trois objets appelés `train_corpus`, `dev_corpus` et `test_corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.conll import ConllCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez le nombre de phrases et le nombre de mots de chaque corpus chargé. Cesc chiffres sont-ils identiques à ceux obtenus pour `dev`et pour `test` à la fin de la Partie 1 ?  On peut obtenir les listes de mots étiquetés avec `tagged_words()` et les listes de phrases avec mots étiquetés avec `tagged_sents()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez la 17e phrase du corpus de développement (avec les étiquettes POS), et les mots 1001 à 1050 du corpus de test (aussi avec leurs POS tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seconde étape**\n",
    "\n",
    "Vous allez maintenant entraîner (sur le corpus `train`) le POS tagger appelé *Averaged Perceptron* fourni par NLTK mais [implémenté par Mathew Honnibal de Explosion.AI](https://explosion.ai/blog/part-of-speech-pos-tagger-in-python).\n",
    "\n",
    "Dans le [package de NLTK avec des taggers](http://www.nltk.org/api/nltk.tag.html), considérez le module `nltk.tag.perceptron`, pour lequel NLTK explique de façon précise l'entraînement (voir *train the model*) et le test.  Vous allez mettre en oeuvre ces étapes pour entraîner le tagger.  Notez que le modèle est enregistré dans un fichier qui doit finir par `.pickle`, et qui est écrasé à chaque entraînement si vous ne changez pas de nom.  Un modèle peut être également chargé dans un tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os # si nécessaire\n",
    "# import nltk # si nécessaire\n",
    "# nltk.download('averaged_perceptron_tagger') # si nécessaire\n",
    "from nltk.tag.perceptron import PerceptronTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptagger = PerceptronTagger(load=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînez ici le tagger sur les données d'entraînement, avec les meilleurs paramètres possibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combien de temps prend l'entraînement ?  Quelle est la taille du fichier modèle résultant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire vos réponses dans cette cellule (en commentaires).\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Évaluez le tagger, d'abord sur les données `dev` puis sur les données `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre code ci-dessous, puis exécuter cette cellule.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez remplir le tableau suivant avec la synthèse des résultats.\n",
    "\n",
    "| Corpus | MaxEnt | MaxEnt   | Avg Perceptron | \n",
    "|--------|--------|----------|---------------|\n",
    "| -      | fourni | entraîné | entraîné |\n",
    "| dev    |   ..   |   ..     |  ..  |\n",
    "| test   |   ..   |   ..     |  ..  |\n",
    "\n",
    "Comment se comparent les deux POS taggers sur le français ?  Écrivez vos conclusions dans cette cellule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin du laboratoire 2  \n",
    "\n",
    "Merci de nettoyer votre feuille, exécuter une dernière fois toutes les instructions, et sauvegarder le résultat.  Ajoutez-la à une archive `.zip` et soumettez-la sur Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
